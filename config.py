# Main loop
LOOP_ITERATIONS = 50

# Network architecture
CONVOLUTIONAL_LAYERS_POSITION = [(1, (3, 3))] # [(64, (3, 3)), (128, (3, 3)), (256, (3, 3)), (512, (3, 3))]
DENSE_POSITION = [1]  # [512, 512, 512]

CONVOLUTIONAL_LAYERS_DECK = [(64, 3), (64, 3)]
DENSE_DECK = [1024, 512]

CONVOLUTIONAL_LAYERS_DRAWN_CARD = [(64, 3), (64, 3)]
DENSE_DRAWN_CARD = [1024, 512]

DENSE_SHARED = [512, 512]
DENSE_VALUE_HEAD = [32, 32]
DENSE_POLICY_HEAD = [512, 512]
USE_BIAS = True

# Self-play
GAME_AMOUNT_SELF_PLAY = 30
POSITION_AMOUNT = 15000
MCTS_SIMS = 100
DEPTH = 1
TURNS_UNTIL_TAU = 20
CPUCT = 0.8
EPSILON = 0.2
ALPHA = 0.8

# Retraining network
TRAINING_ITERATIONS = 10
BATCH_SIZE = 128
EPOCHS = 1
GAMMA = 0.5
LAMBDA = 0.5
VALIDATION_SPLIT = 0.2
REG_CONST = 1e-4
LEARNING_RATE = 1e-3
MOMENTUM = 0.5

# Evaluating network
GAME_AMOUNT_EVALUATION = 25
EVALUATION_FREQUENCY = 5
WINNING_THRESHOLD = 1

# Play versions
GAME_AMOUNT_PLAY_VERSIONS = 20

# Play-test
GAME_AMOUNT_PLAY_TEST = 4

# General
SAVE_PATH = "save_folder/"
