# Main loop
LOOP_ITERATIONS = 50

# Network architecture
CONVOLUTIONAL_LAYER = [(128, (3, 3)), (256, (3, 3)), (256, (3, 3))]
DENSE_POSITION = [512, 512]
DENSE_DECK = [128, 128]
DENSE_DRAWN_CARD = [128, 128]
DENSE_SHARED = [512, 512]
DENSE_VALUE_HEAD = [32, 32]
DENSE_POLICY_HEAD = [512, 512]
USE_BIAS = True

# Self-play
GAME_AMOUNT_SELF_PLAY = 1
POSITION_AMOUNT = 2
MCTS_SIMS = 100
TURNS_UNTIL_TAU = 20
CPUCT = 1.7
EPSILON = 0.2
ALPHA = 0.8

# Retraining network
TRAINING_ITERATIONS = 3
BATCH_SIZE = 2
EPOCHS = 1
VALIDATION_SPLIT = 0.2
REG_CONST = 1e-4
LEARNING_RATE = 1e-3
MOMENTUM = 0.5

# Evaluating network
GAME_AMOUNT_EVALUATION = 1
EVALUATION_FREQUENCY = 5
WINNING_THRESHOLD = 1

# Play versions
GAME_AMOUNT_PLAY_VERSIONS = 20

# Play-test
GAME_AMOUNT_PLAY_TEST = 4

# General
SAVE_PATH = "save_folder/"
